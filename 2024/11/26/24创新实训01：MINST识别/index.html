<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>24创新实训01：MNIST手写数据集预测（ML） | 悲伤虾滑蛋</title><meta name="author" content="Zhou Chenyu"><meta name="copyright" content="Zhou Chenyu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="2023-2024 学年秋季学期 创新创业实训一、实训过程简述1 实训概况、实训过程实践概况:本学期在马老师的指导下,借助网络资源学习了机器学习和深度学习的一些 入门知识,了解了一些基础的概念,模型背后的数学原理,也动手实践做了一个通过全连接 神经网络模型来预测手写数字集的小项目,加深了我对理论知识的理解。 实践过程:学期初,我在网络上学习了北京邮电大学鲁鹏老师的计算机视觉与深度学习 的课程,这门">
<meta property="og:type" content="article">
<meta property="og:title" content="24创新实训01：MNIST手写数据集预测（ML）">
<meta property="og:url" content="https://captainjack-ai.github.io/2024/11/26/24%E5%88%9B%E6%96%B0%E5%AE%9E%E8%AE%AD01%EF%BC%9AMINST%E8%AF%86%E5%88%AB/index.html">
<meta property="og:site_name" content="悲伤虾滑蛋">
<meta property="og:description" content="2023-2024 学年秋季学期 创新创业实训一、实训过程简述1 实训概况、实训过程实践概况:本学期在马老师的指导下,借助网络资源学习了机器学习和深度学习的一些 入门知识,了解了一些基础的概念,模型背后的数学原理,也动手实践做了一个通过全连接 神经网络模型来预测手写数字集的小项目,加深了我对理论知识的理解。 实践过程:学期初,我在网络上学习了北京邮电大学鲁鹏老师的计算机视觉与深度学习 的课程,这门">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://captainjack-ai.github.io/img/3.png">
<meta property="article:published_time" content="2024-11-26T08:37:19.000Z">
<meta property="article:modified_time" content="2024-11-27T13:11:57.524Z">
<meta property="article:author" content="Zhou Chenyu">
<meta property="article:tag" content="Practice">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://captainjack-ai.github.io/img/3.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://captainjack-ai.github.io/2024/11/26/24%E5%88%9B%E6%96%B0%E5%AE%9E%E8%AE%AD01%EF%BC%9AMINST%E8%AF%86%E5%88%AB/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":400,"highlightFullpage":true,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":250,"languages":{"author":"作者: Zhou Chenyu","link":"链接: ","source":"来源: 悲伤虾滑蛋","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'medium_zoom',
  Snackbar: {"chs_to_cht":"已切换为繁体中文","cht_to_chs":"已切换为简体中文","day_to_night":"已切换为深色模式","night_to_day":"已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '24创新实训01：MNIST手写数据集预测（ML）',
  isPost: true,
  isHome: false,
  isHighlightShrink: undefined,
  isToc: true,
  isShuoshuo: false
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">6</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url(/img/3.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">悲伤虾滑蛋</span></a><a class="nav-page-title" href="/"><span class="site-name">24创新实训01：MNIST手写数据集预测（ML）</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">24创新实训01：MNIST手写数据集预测（ML）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-11-26T08:37:19.000Z" title="发表于 2024-11-26 16:37:19">2024-11-26</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-11-27T13:11:57.524Z" title="更新于 2024-11-27 21:11:57">2024-11-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/">计算机科学</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">4.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>14分钟</span></span><span class="post-meta-separator">|</span><span id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span class="waline-pageview-count" data-path="/2024/11/26/24%E5%88%9B%E6%96%B0%E5%AE%9E%E8%AE%AD01%EF%BC%9AMINST%E8%AF%86%E5%88%AB/"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2024/11/26/24%E5%88%9B%E6%96%B0%E5%AE%9E%E8%AE%AD01%EF%BC%9AMINST%E8%AF%86%E5%88%AB/#post-comment"><span class="waline-comment-count" data-path="/2024/11/26/24%E5%88%9B%E6%96%B0%E5%AE%9E%E8%AE%AD01%EF%BC%9AMINST%E8%AF%86%E5%88%AB/"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="2023-2024-学年秋季学期-创新创业实训"><a href="#2023-2024-学年秋季学期-创新创业实训" class="headerlink" title="2023-2024 学年秋季学期 创新创业实训"></a>2023-2024 学年秋季学期 创新创业实训</h1><h2 id="一、实训过程简述"><a href="#一、实训过程简述" class="headerlink" title="一、实训过程简述"></a>一、实训过程简述</h2><h3 id="1-实训概况、实训过程"><a href="#1-实训概况、实训过程" class="headerlink" title="1 实训概况、实训过程"></a>1 实训概况、实训过程</h3><p>实践概况:本学期在马老师的指导下,借助网络资源学习了机器学习和深度学习的一些 入门知识,了解了一些基础的概念,模型背后的数学原理,也动手实践做了一个通过全连接 神经网络模型来预测手写数字集的小项目,加深了我对理论知识的理解。</p>
<p>实践过程:学期初,我在网络上学习了北京邮电大学鲁鹏老师的计算机视觉与深度学习 的课程,这门课主要是讲解一些分类器模型背后的数学原理,我分别听了图像分类任务,线 性分类器,全连接神经网络以及卷积的相关课程。学习了如何构建模型、通过损失函数刻画 模型性能,并利用优化算法更新模型权值等基础的机器学习与深度学习知识。</p>
<p>更为具体一点来说,在课程中我学习到了多类支撑向量机损失,交叉熵损失,正则损失 三种具有不同的特点的损失函数来刻画模型的预测性能;此外优化算法方面,我了解了梯度 下降算法,以及在其基础上优化形成的小批量随机梯度下降算法。全连接神经网络方面,我 了解了激活函数对线性分类器进行的非线性操作,使得模型可以处理更为复杂的分类任务; 借助计算图实现前向传播和反向传播,实现导数的计算从而进行权值的更新等等; 在学习了一些理论知识并了解了基础模型的数学背景之后,我想要做一个实际的小项目 来实践我学到的知识,于是我找到了 Mnist 手写数据集,想要利用一个简单的全连接神经网 络来实现对这个数据集的预测。经过查阅资料,学习了 Pytorch 的一些操作之后,我成功实 现了对这个数据集的预测,应用到了很多之前学到的理论知识,加深了对相关理论知识的理 解。</p>
<h3 id="2-实训体会及建议"><a href="#2-实训体会及建议" class="headerlink" title="2 实训体会及建议"></a>2 实训体会及建议</h3><p>在实训过程中,老师给予了我们很好的平台,让我们能够及时的和其他同学一起交流 学习的内容,不仅能够学到每个人分享的知识,也能够了解大家的学习路径和方法。我觉 得这种学习方式对于刚刚入门机器学习和深度学习的我们非常有效。在实训中不断发现问 题,解决问题的过程也给我一种满满的获得感。同时,实训让我了解了机器学习的基础逻 辑,这也让我对这个领域产生了浓厚的兴趣,想要在之后的学习过程中进一步地去学习这些 知识。</p>
<h2 id="二、报告正文"><a href="#二、报告正文" class="headerlink" title="二、报告正文"></a>二、报告正文</h2><p><strong>全连接神经网络实现手写数据集预测</strong></p>
<p>23121608 周宸宇</p>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>本文旨在使用全连接神经网络(FCNN)对 MNIST 手写数字数据集进行分类预测。通过采 用 PyTorch 框架,我们构建了一个多层神经网络模型,并使用 Adam 优化器和负对数似然损 失函数对其进行训练与优化。在本报告中,我们将介绍 MNIST 数据集的特点、模型的设计与 实现,并通过实验结果验证其性能。最终,模型在测试集上达到了较高的分类准确率,验证 了 FCNN 在该任务中的有效性。 关键字:全连接神经网络,MNIST,PyTorch,图像分类,深度学习</p>
<h3 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h3><p>随着人工智能技术的发展,图像分类任务得到了广泛的研究与应用。MNIST手写数字数 据集是图像分类领域的一个经典数据集,广泛用于验证各种机器学习算法的有效性。本文采 用全连接神经网络(Fully Connected Neural Network, FCNN)解决MNIST数据集的分类问 题。全连接神经网络能够通过多层结构逐步提取图像的特征,并将其用于分类。本项目通过 对FCNN进行设计与训练,探索其在手写数字分类任务中的表现。</p>
<h3 id="2-问题分析"><a href="#2-问题分析" class="headerlink" title="2 问题分析"></a>2 问题分析</h3><p>MNIST数据集由60,000张训练图像和10,000张测试图像组成,每张图像为28×28像素的 灰度图,表示从0到9的手写数字。每个像素的灰度值在0到255之间。任务目标是通过神经网 络将这些图像分类到10个类别中。</p>
<p>Figure 1:MNIST 图像识别数据集</p>
<p>全连接神经网络通过线性映射和非线性激活函数的组合,对高维数据进行处理和分类。</p>
<p>该问题的主要挑战包括:</p>
<ol>
<li><p>高维输入:每张图像被展平成一个784维向量,需要有效提取特征。</p>
</li>
<li><p>计算复杂度:全连接神经网络的参数较多,可能导致训练时间过长或过拟合。</p>
</li>
<li><p>泛化能力:如何保证在测试集上的良好性能,避免过拟合是训练中的重要挑战。</p>
</li>
</ol>
<h3 id="3-技术实现"><a href="#3-技术实现" class="headerlink" title="3 技术实现"></a>3 技术实现</h3><h4 id="3-1-加载MNIST数据集"><a href="#3-1-加载MNIST数据集" class="headerlink" title="3.1 加载MNIST数据集"></a>3.1 加载MNIST数据集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> train_batch_size = <span class="number">64</span> test_batch_size = <span class="number">1000</span> img_size = <span class="number">28</span> <span class="keyword">def</span> <span class="title function_">get_dataloader</span>(<span class="params">train=<span class="literal">True</span></span>):</span><br><span class="line"> \<span class="comment">#准备数据集,其中 0.1307,0.3081 为 MNIST 数据的均值和标准差,这样操作能够对其 进行标准化</span></span><br><span class="line"> \<span class="comment">#因为 MNIST 只有一个通道(黑白图片),所以元组中只有一个值 dataset =</span></span><br><span class="line">torchvision.datasets.MNIST(<span class="string">&#x27;/Users/jackchen/Jupyter_notebook/data&#x27;</span>, train=train, download=<span class="literal">True</span>, transform=torchvision.transforms.Compose([</span><br><span class="line"> torchvision.transforms.ToTensor(),</span><br><span class="line">torchvision.transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,)),])) \<span class="comment">#准备数据迭代器 batch_size = train_batch_size if train else test_batch_size dataloader =</span></span><br><span class="line">torch.utils.data.DataLoader(dataset,batch_size=batch_size,shuffle=Tru e)</span><br><span class="line"><span class="keyword">return</span> dataloader </span><br></pre></td></tr></table></figure>
<h4 id="3-2-网络结构设计"><a href="#3-2-网络结构设计" class="headerlink" title="3.2 网络结构设计"></a>3.2 网络结构设计</h4><p>我们设计了一个全连接神经网络MnistNet,该网络包含若干线性层和ReLU激活函数:</p>
<ul>
<li><p>输入层:接收28×28像素的展平输入(784维向量)。这一步将图像的二维像素数据拉平成 一维向量,作为神经网络的输入。</p>
</li>
<li><p>隐藏层:若干全连接层,使用ReLU激活函数。</p>
<blockquote>
<p>ReLU(修正线性单元)是一种常见的激活函数,当输入x为正数时,ReLU输出为x本 身;当输入为负数时,ReLU输出为0。通过这一简单的非线性变换,ReLU能够引入网络所 需的复杂性,帮助模型学习非线性特征。与其他激活函数(如Sigmoid或Tanh)相比, ReLU有几个显著优势。首先,它的计算效率非常高,输出仅依赖于判断输入是否大于0, 这使得它在大规模深度神经网络训练中非常流行。其次,ReLU能有效缓解梯度消失问题。 在反向传播时,ReLU在正数区域的梯度为1,不会像Sigmoid那样导致梯度逐渐变小,使得 深层网络的训练更加顺利。</p>
</blockquote>
</li>
<li><p>输出层:一个具有 10 个神经元的全连接层,每个神经元表示一个数字类别的预测概率。</p>
</li>
</ul>
<p>通过 Softmax 激活函数将输出层转化为概率分布,模型能够输出每个类别的概率,最终 选择最大概率对应的类别作为预测结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入相关库</span></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms <span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="keyword">import</span> torch <span class="keyword">import</span> torchvision <span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F <span class="keyword">from</span> torch <span class="keyword">import</span> nn <span class="keyword">from</span> torch <span class="keyword">import</span> optim <span class="keyword">class</span> <span class="title class_">MnistNet</span>(torch.nn.Module):</span><br><span class="line"> <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line"> <span class="built_in">super</span>(MnistNet,<span class="variable language_">self</span>).__init__() <span class="variable language_">self</span>.fc1 = torch.nn.Linear(<span class="number">28</span>*<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line"> <span class="variable language_">self</span>.fc2 = torch.nn.Linear(<span class="number">28</span>,<span class="number">10</span>)</span><br><span class="line"> <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>): \<span class="comment"># 输入层 x = x.view(-1,28*28*1)\#[batch_size,28*28]</span></span><br><span class="line"> \<span class="comment"># 隐藏层 x = self.fc1(x) \#[batch_size,28]</span></span><br><span class="line"> \<span class="comment"># 隐藏层的激活函数 x = F.relu(x) \#[batch_size,28] \# 输出层 x = self.fc2(x) \#[batch_size,10]</span></span><br><span class="line"> \<span class="comment"># 输出层的激活函数 out = F.log_softmax(x,dim=-1) \#[batch_size,10]</span></span><br><span class="line"> <span class="keyword">return</span> out mnist_net = MnistNet() \<span class="comment"># 初始化网络模型</span></span><br></pre></td></tr></table></figure>
<h4 id="3-3-模型训练"><a href="#3-3-模型训练" class="headerlink" title="3.3 模型训练"></a>3.3 模型训练</h4><p>我们使用Adam优化器对模型进行训练,并使用负对数似然损失函数来计算分类误差。在 使用代码说明之前,我们先解释一下Adam优化器和对数似然损失:<br>Adam(Adaptive Moment Estimation)是一种自适应梯度优化算法,广泛用于神经网络 的训练。相较于传统的随机梯度下降(SGD),Adam 结合了动量和自适应学习率的优点,使 参数的更新速度更快且更具稳定性。Adam 尤其适用于处理稀疏梯度和高维数据的优化问 题,在深度学习中具有显著的效果。</p>
<p>Adam 的工作机制依赖于两个动量项的计算:</p>
<ol>
<li><p>第一个动量(均值动量):Adam 计算梯度的指数加权平均,用于估计梯度的一阶 矩(即梯度的均值)。该动量项有助于捕捉梯度的整体趋势,类似于 SGD 中引入动量的做 法,通过跟踪过去的梯度信息来平滑更新方向,从而避免参数更新频繁波动。</p>
</li>
<li><p>第二个动量(方差动量):Adam 计算梯度平方的指数加权平均,用于估计梯度的 二阶矩(即方差)。通过监测梯度变化的方差,Adam 可以动态调整学习率,降低高方差的梯 度更新步伐,避免在梯度变化较大的方向上出现不稳定更新。</p>
</li>
</ol>
<p>在更新参数时,Adam 将每个动量项分别进行偏差校正,使得初始阶段动量估计更加准 确,进而对每个参数的学习率进行自动调整。Adam 的具体更新规则如下:</p>
<ul>
<li>学习率调整:通过动量项的偏差校正和自适应学习率,Adam 不需要在训练过程 中频繁手动调整学习率。它能够自动适应不同参数的更新速度,使得训练在复杂数据上更高 效。</li>
</ul>
<p>Adam 的核心优势如下:</p>
<ul>
<li><p>高效稳定的更新:动量结合自适应学习率,使得 Adam 在参数空间的更新更加平 滑,有助于减少梯度变化剧烈时的震荡问题,提升训练的稳定性。</p>
</li>
<li><p>自动调节学习率:无需手动调整学习率,Adam 在训练复杂模型和大数据集上尤 其有效,能够自动适应不同维度和参数的学习步伐。</p>
</li>
<li><p>适用广泛:Adam 适合高维优化问题,能够处理稀疏梯度问题,这使得其在 NLP、图像分类、生成对抗网络等深度学习领域广泛应用。</p>
</li>
</ul>
<p>在 MNIST 数据集的分类任务中,Adam 能加速收敛过程,使 MnistNet 在较短时间内达 到较高的准确率,提升模型的泛化能力。同时,Adam 在参数更新上的自适应性能够保证训 练稳定性,减少手动调参的工作量,从而提升开发效率。</p>
<p>负对数似然损失(Negative Log-Likelihood Loss, NLL),是一种基于概率最大化的 损失函数,用于衡量模型预测分布与真实分布之间的差异。其设计初衷在于最大化模型在正 确类别上的预测概率,因此广泛应用于分类任务。对数似然损失通过最大化模型在正确标签 上的概率,使模型在每次迭代中逐渐提高对真实标签的预测置信度。</p>
<p>定义与公式: 假设分类模型输出一个样本属于各个类别的概率分布。给定一个样本 x 及其真实类别标签 y,若模型预测类别 y 的概率为 p(y|x),则该样本的对数似然损失定义为:</p>
<p><img src="/img/123456.png" alt="123456.png"></p>
<p>其中,N 表示样本数,p(yi|xi) 是模型对样本 xi 在真实类别 yi 下的预测概率。</p>
<p>直观解释:</p>
<p>对数似然损失的目的是提升模型在正确类别上的预测概率,使得模型在面对真实标签 时能给出较高的预测置信度。直观上,当模型预测结果与真实类别接近时,模型的损失较 小;当预测概率较低时,损失会显著增大。具体而言:</p>
<ul>
<li>高度自信:如果模型对真实类别的预测概率接近 1,则对数似然损失趋近于 0。 - 高度不自信:如果预测概率接近 0,模型在真实标签上的置信度低,损失值会急 剧增大。</li>
</ul>
<p>因此,通过最小化对数似然损失,模型被优化为逐步提高对正确类别的预测自信度, 从而更精确地反映样本的实际分类结果。</p>
<p>应用与特点:</p>
<ol>
<li><p>分类任务的核心损失:对数似然损失特别适合多类别分类任务,尤其在多分类神 经网络模型中,通常与Softmax激活函数配合使用,以便将输出转化为类别概率。</p>
</li>
<li><p>对错误预测敏感:当模型输出的预测概率与真实标签偏差较大时,对数似然损失 会显著增大,促使模型在训练过程中更快修正偏差。</p>
</li>
<li><p>与交叉熵损失的关系:在分类问题中,负对数似然损失与交叉熵损失(Cross-<br>Entropy Loss)在形式上等价,并且在多类别分类任务中,两者常被交替使用。</p>
</li>
</ol>
<p>对数似然损失基于最大似然估计,通过最小化损失,模型逐步调整参数,使得预测分 布更符合数据的真实分布。模型参数优化后,能够在测试集上对未见样本提供稳健的预测概 率。因此,对数似然损失在提升分类任务的泛化能力与优化效果上具有理论与实用价值。</p>
<p>Adam优化器和对数似然损失的结合,使得模型在复杂任务中的训练过程更加高效,损 失函数衡量误差,优化器则根据误差调整模型的参数,二者配合实现模型的逐步优化。</p>
<p>以下是代码实现部分:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">def</span> <span class="title function_">Train</span>(<span class="params">Epoch</span>):</span><br><span class="line"> mnist_net.train(<span class="literal">True</span>) \<span class="comment"># 启用训练模式 train_dataloader = get_dataloader(True) \# 获取训练集数据 print(&quot;开始训练:&quot;)</span></span><br><span class="line"><span class="keyword">for</span> idx, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataloader): </span><br><span class="line">\<span class="comment"># 遍历每个批次 optimizer.zero_grad() \# 清除先前梯度 output = mnist_net(data) \# 前向传播,计算输出 loss = F.nll_loss(output, target) \# 计算损失 loss.backward() \# 反向传播计算梯度 optimizer.step() \# 更新模型参数 if idx % 200 == 0:</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Train Epoch: <span class="subst">&#123;epoch&#125;</span> [<span class="subst">&#123;idx *</span></span></span><br><span class="line"><span class="subst"><span class="string"><span class="built_in">len</span>(data)&#125;</span>/<span class="subst">&#123;<span class="built_in">len</span>(train_dataloader.dataset)&#125;</span> (<span class="subst">&#123;<span class="number">100.</span> * idx /</span></span></span><br><span class="line"><span class="subst"><span class="string"><span class="built_in">len</span>(train dataloader):<span class="number">.0</span>f&#125;</span>%)]\tLoss: <span class="subst">&#123;loss.item():<span class="number">.6</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">train_loss_list.append(loss.item()) \<span class="comment"># 记录损失 train_count_list.append(idx * train_batch_size + (epoch - 1) *</span></span><br><span class="line"><span class="built_in">len</span>(train_dataloader)) \<span class="comment"># 记录进度 print(&quot;结束训练。&quot;)</span></span><br><span class="line">epoch = <span class="number">3</span> \<span class="comment"># 训练的轮次 for i in range(epoch):</span></span><br><span class="line">train(i)</span><br><span class="line">test()</span><br><span class="line">\<span class="comment">#</span></span><br></pre></td></tr></table></figure>
<p><img src="/img/12345.png" alt="12345.png"></p>
<h4 id="3-4-模型评估"><a href="#3-4-模型评估" class="headerlink" title="3.4 模型评估"></a>3.4 模型评估</h4><p>测试时,不计算梯度,以提高效率。我们计算模型的平均损失和分类准确率:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">test_loss = <span class="number">0</span> correct = <span class="number">0</span> mnist net.<span class="built_in">eval</span>()</span><br><span class="line">test_dataloader = get_dataloader(train=<span class="literal">False</span>)</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line"> <span class="keyword">for</span> data, target <span class="keyword">in</span> test_dataloader: output = mnist_net(data)</span><br><span class="line"> test_loss += F.nll_loss(output, target, reduction=<span class="string">&#x27;sum&#x27;</span>).item()</span><br><span class="line"> pred = output.data.<span class="built_in">max</span>(<span class="number">1</span>, keepdim=<span class="literal">True</span>)[<span class="number">1</span>] \<span class="comment">#获取最大值的位置,[batch_size,1]</span></span><br><span class="line"> correct += pred.eq(target.data.view_as(pred)).<span class="built_in">sum</span>() test_loss /= <span class="built_in">len</span>(test_dataloader.dataset)</span><br><span class="line"> <span class="built_in">print</span>(<span class="string">&#x27;\nTest set: Avg. loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.2f&#125;%)\n&#x27;</span>.<span class="built_in">format</span>( test_loss, correct, <span class="built_in">len</span>(test_dataloader.dataset), <span class="number">100.</span> * correct / <span class="built_in">len</span>(test_dataloader.dataset)))</span><br><span class="line">test()</span><br></pre></td></tr></table></figure>
<p>Figure 3:模型评估输出结果</p>
<h4 id="3-5-模型的保存与加载"><a href="#3-5-模型的保存与加载" class="headerlink" title="3.5 模型的保存与加载"></a>3.5 模型的保存与加载</h4><p>为了复现训练结果,我们使用torch.save和torch.load来保存和加载模型参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">\<span class="comment"># 保存模型参数 </span></span><br><span class="line">torch.save(mnist_net.state_dict(), <span class="string">&quot;model/mnist_net.pt&quot;</span>) \<span class="comment"># 保存模型 </span></span><br><span class="line">torch.save(optimizer.state_dict(), <span class="string">&#x27;results/mnist_optimizer.pt&#x27;</span>) \<span class="comment"># 保存优化</span></span><br><span class="line">\<span class="comment"># 加载模型参数 </span></span><br><span class="line">mnist_net.load_state_dict(torch.load(<span class="string">&quot;model/mnist_net.pt&quot;</span>))\<span class="comment"># 加载模型 </span></span><br><span class="line">optimizer.load_state_dict(torch.load(<span class="string">&quot;results/mnist_optimizer.pt&quot;</span>)) </span><br><span class="line">\<span class="comment"># 加载优化器</span></span><br></pre></td></tr></table></figure>
<h3 id="4-分析总结"><a href="#4-分析总结" class="headerlink" title="4 分析总结"></a>4 分析总结</h3><p>通过对 MNIST 数据集的分类任务研究,使用全连接神经网络(FCNN)模型取得了较高的 测试集准确率,表明该网络能够有效提取图像特征并准确完成分类。然而,FCNN 对图像数 据的处理方式可能存在局限性,因为它并未利用图像的空间结构信息。随着学习的深入,未 来可以尝试引入卷积神经网络(CNN),这种网络更适合图像数据,能够提取出更丰富的局部 特征,从而有望进一步提升模型性能。此外,针对 FCNN 模型,可以通过调节模型参数(如 层数和节点数)、学习率以及优化器(如使用 Adam 或 RMSprop)等,进一步提升模型的泛化 能力和稳定性。</p>
<p>最后,感谢马老师本学期给予我们的指导和帮助!</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] CSDN 技术社区 <a target="_blank" rel="noopener" href="https://blog.csdn.net/xjm850552586/article/details/109171016">https://blog.csdn.net/xjm850552586/article/details/109171016</a> [2] 知乎 知识社区 <a target="_blank" rel="noopener" href="https://www.zhihu.com/tardis/zm/art/492674150?source_id=1005">https://www.zhihu.com/tardis/zm/art/492674150?source_id=1005</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://captainjack-ai.github.io">Zhou Chenyu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://captainjack-ai.github.io/2024/11/26/24%E5%88%9B%E6%96%B0%E5%AE%9E%E8%AE%AD01%EF%BC%9AMINST%E8%AF%86%E5%88%AB/">https://captainjack-ai.github.io/2024/11/26/24%E5%88%9B%E6%96%B0%E5%AE%9E%E8%AE%AD01%EF%BC%9AMINST%E8%AF%86%E5%88%AB/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://captainjack-ai.github.io" target="_blank">悲伤虾滑蛋</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Practice/">Practice</a></div><div class="post-share"><div class="social-share" data-image="/img/3.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2024/11/27/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%8402%EF%BC%9A%E9%9D%99%E6%80%81%E9%93%BE%E8%A1%A8/" title="数据结构02：静态链表"><img class="cover" src="/img/datastructure.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">数据结构02：静态链表</div></div><div class="info-2"><div class="info-item-1">1、引言本文主要是对动态链表和静态链表的区别进行原理上的讲解分析，先通过对顺序表和动态链表概念和特点的原理性介绍，进而引申出静态链表的作用，以及其概念。通过这些原理性的概述，最后总结归纳出动态链表和静态链表的区别。本文不对代码进行额外的讲解，只对原理进行分析以加深基础的认识，相关概念的代码应用可以另行在网上进行搜索详细学习。    2、顺序表和动态链表的特点首先需要明白的是，顺序表和链表都是线性表，即线性存储结构。使用线性表存储数据的方式可以这样理解，即“把所有数据用一根线串起来，再存储到物理空间中”。 如下图左边将数据依次存储在连续的整块物理空间中，这种存储结构称为顺序存储结构（简称顺序表）；下图右边数据分散的存储在物理空间中，通过一根线保存着它们之间的逻辑关系，这种存储结构称为链式存储结构（简称链表）。可以看出每一个数据按照“一对一”的关系按照次序逐个排列。  2.1 顺序表存储结构顺序表对数据的物理存储结构有要求，需预先申请一整块足够大的存储空间，然后将数据依次存储起来，数据之间紧密贴合，不留一丝空隙。如下图所示，顺序表数据的 ‘一对一’...</div></div></div></a><a class="pagination-related" href="/2024/11/26/24%E5%A4%8F%E5%AD%A3%E5%AE%9E%E8%AE%AD01%EF%BC%9A%E6%8E%92%E5%BA%8F%EF%BC%88Sort%EF%BC%89/" title="24夏季实训01：排序（Sort）"><img class="cover" src="/img/2.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">24夏季实训01：排序（Sort）</div></div><div class="info-2"><div class="info-item-1">经典排序算法的优化及其测试2023-2024 夏季学期《计算机程序设计实训》课程报告(计算机工程与科学学院)摘 要 本文主要研究常用的经典排序算法在不同的数据规模,数据类型,数据分布的情况下的运行 效率,并将通过对冒泡排序、选择排序、快速排序三种经典算法的优化研究,探索不同排序算法在不同数 据场景下的表现。对所得出的数据,将以图表的方式做出具体分析。 关键词 排序;优化算法;算法评析; Optimization And Testing Of Classical Sorting Algorithm2023-2024 SUMMER SEMESTER “COMPUTER PROGRAMMING TRAINING”COURSE REPORT (School of Computer Engineering and Science)Abstract This paper mainly studies the efficiency of commonly used classical sorting algorithms in the case of different data...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2024/11/26/24%E5%A4%8F%E5%AD%A3%E5%AE%9E%E8%AE%AD01%EF%BC%9A%E6%8E%92%E5%BA%8F%EF%BC%88Sort%EF%BC%89/" title="24夏季实训01：排序（Sort）"><img class="cover" src="/img/2.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-26</div><div class="info-item-2">24夏季实训01：排序（Sort）</div></div><div class="info-2"><div class="info-item-1">经典排序算法的优化及其测试2023-2024 夏季学期《计算机程序设计实训》课程报告(计算机工程与科学学院)摘 要 本文主要研究常用的经典排序算法在不同的数据规模,数据类型,数据分布的情况下的运行 效率,并将通过对冒泡排序、选择排序、快速排序三种经典算法的优化研究,探索不同排序算法在不同数 据场景下的表现。对所得出的数据,将以图表的方式做出具体分析。 关键词 排序;优化算法;算法评析; Optimization And Testing Of Classical Sorting Algorithm2023-2024 SUMMER SEMESTER “COMPUTER PROGRAMMING TRAINING”COURSE REPORT (School of Computer Engineering and Science)Abstract This paper mainly studies the efficiency of commonly used classical sorting algorithms in the case of different data...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="waline-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Zhou Chenyu</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">6</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/CaptainJack-ai" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:shuzhouchenyu@icloud.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content"><p>欢迎来到我的个人网站！</p>
<p>🙋‍♂️是谁？<br>—— 一个代码工匠,热衷解决“BUG星人”的入侵;</p>
<p>🎵 会做啥？<br>—— 不止会码代码，还会弹吉他和玩架子鼓！</p>
<p>🏓 兴趣？<br>—— 乒乓球、音乐、写博客，偶尔研究新技术，整点小创新！</p>
<p>欢迎探索我的网站，有疑问或建议，直接留言吧！😄<br>Enjoy your stay 🎉</p>
</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#2023-2024-%E5%AD%A6%E5%B9%B4%E7%A7%8B%E5%AD%A3%E5%AD%A6%E6%9C%9F-%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%AE%9E%E8%AE%AD"><span class="toc-number">1.</span> <span class="toc-text">2023-2024 学年秋季学期 创新创业实训</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%AE%9E%E8%AE%AD%E8%BF%87%E7%A8%8B%E7%AE%80%E8%BF%B0"><span class="toc-number">1.1.</span> <span class="toc-text">一、实训过程简述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%AE%9E%E8%AE%AD%E6%A6%82%E5%86%B5%E3%80%81%E5%AE%9E%E8%AE%AD%E8%BF%87%E7%A8%8B"><span class="toc-number">1.1.1.</span> <span class="toc-text">1 实训概况、实训过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%AE%9E%E8%AE%AD%E4%BD%93%E4%BC%9A%E5%8F%8A%E5%BB%BA%E8%AE%AE"><span class="toc-number">1.1.2.</span> <span class="toc-text">2 实训体会及建议</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E6%8A%A5%E5%91%8A%E6%AD%A3%E6%96%87"><span class="toc-number">1.2.</span> <span class="toc-text">二、报告正文</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.2.1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%BC%95%E8%A8%80"><span class="toc-number">1.2.2.</span> <span class="toc-text">1 引言</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90"><span class="toc-number">1.2.3.</span> <span class="toc-text">2 问题分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%8A%80%E6%9C%AF%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.2.4.</span> <span class="toc-text">3 技术实现</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-%E5%8A%A0%E8%BD%BDMNIST%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.2.4.1.</span> <span class="toc-text">3.1 加载MNIST数据集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1"><span class="toc-number">1.2.4.2.</span> <span class="toc-text">3.2 网络结构设计</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">1.2.4.3.</span> <span class="toc-text">3.3 模型训练</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0"><span class="toc-number">1.2.4.4.</span> <span class="toc-text">3.4 模型评估</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-5-%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD"><span class="toc-number">1.2.4.5.</span> <span class="toc-text">3.5 模型的保存与加载</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%88%86%E6%9E%90%E6%80%BB%E7%BB%93"><span class="toc-number">1.2.5.</span> <span class="toc-text">4 分析总结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-number">1.2.6.</span> <span class="toc-text">参考文献</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/11/27/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%8402%EF%BC%9A%E9%9D%99%E6%80%81%E9%93%BE%E8%A1%A8/" title="数据结构02：静态链表"><img src="/img/datastructure.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="数据结构02：静态链表"/></a><div class="content"><a class="title" href="/2024/11/27/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%8402%EF%BC%9A%E9%9D%99%E6%80%81%E9%93%BE%E8%A1%A8/" title="数据结构02：静态链表">数据结构02：静态链表</a><time datetime="2024-11-27T15:41:49.000Z" title="发表于 2024-11-27 23:41:49">2024-11-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/11/26/24%E5%88%9B%E6%96%B0%E5%AE%9E%E8%AE%AD01%EF%BC%9AMINST%E8%AF%86%E5%88%AB/" title="24创新实训01：MNIST手写数据集预测（ML）"><img src="/img/3.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="24创新实训01：MNIST手写数据集预测（ML）"/></a><div class="content"><a class="title" href="/2024/11/26/24%E5%88%9B%E6%96%B0%E5%AE%9E%E8%AE%AD01%EF%BC%9AMINST%E8%AF%86%E5%88%AB/" title="24创新实训01：MNIST手写数据集预测（ML）">24创新实训01：MNIST手写数据集预测（ML）</a><time datetime="2024-11-26T08:37:19.000Z" title="发表于 2024-11-26 16:37:19">2024-11-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/11/26/24%E5%A4%8F%E5%AD%A3%E5%AE%9E%E8%AE%AD01%EF%BC%9A%E6%8E%92%E5%BA%8F%EF%BC%88Sort%EF%BC%89/" title="24夏季实训01：排序（Sort）"><img src="/img/2.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="24夏季实训01：排序（Sort）"/></a><div class="content"><a class="title" href="/2024/11/26/24%E5%A4%8F%E5%AD%A3%E5%AE%9E%E8%AE%AD01%EF%BC%9A%E6%8E%92%E5%BA%8F%EF%BC%88Sort%EF%BC%89/" title="24夏季实训01：排序（Sort）">24夏季实训01：排序（Sort）</a><time datetime="2024-11-26T06:52:19.000Z" title="发表于 2024-11-26 14:52:19">2024-11-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/11/26/%E5%8D%B7%E7%A7%AF%EF%BC%88Convolution%EF%BC%89/" title="信号处理02：卷积（Convolution）"><img src="/img/1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="信号处理02：卷积（Convolution）"/></a><div class="content"><a class="title" href="/2024/11/26/%E5%8D%B7%E7%A7%AF%EF%BC%88Convolution%EF%BC%89/" title="信号处理02：卷积（Convolution）">信号处理02：卷积（Convolution）</a><time datetime="2024-11-26T04:52:19.000Z" title="发表于 2024-11-26 12:52:19">2024-11-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/11/25/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%8401%EF%BC%9A%E5%8D%95%E9%93%BE%E8%A1%A8%E7%B1%BB%E6%A8%A1%E7%89%88%E8%AE%BE%E8%AE%A1/" title="数据结构01：单链表模板类设计"><img src="/img/datastructure.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="数据结构01：单链表模板类设计"/></a><div class="content"><a class="title" href="/2024/11/25/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%8401%EF%BC%9A%E5%8D%95%E9%93%BE%E8%A1%A8%E7%B1%BB%E6%A8%A1%E7%89%88%E8%AE%BE%E8%AE%A1/" title="数据结构01：单链表模板类设计">数据结构01：单链表模板类设计</a><time datetime="2024-11-25T13:22:19.000Z" title="发表于 2024-11-25 21:22:19">2024-11-25</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(/img/3.png);"><div id="footer-wrap"><div class="copyright">&copy;2024 By Zhou Chenyu</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>(() => {
  const panguFn = () => {
    if (typeof pangu === 'object') pangu.autoSpacingPage()
    else {
      btf.getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
        .then(() => {
          pangu.autoSpacingPage()
        })
    }
  }

  const panguInit = () => {
    if (false){
      GLOBAL_CONFIG_SITE.isPost && panguFn()
    } else {
      panguFn()
    }
  }

  btf.addGlobalFn('pjaxComplete', panguInit, 'pangu')
  document.addEventListener('DOMContentLoaded', panguInit)
})()</script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  let initFn = window.walineFn || null
  const isShuoshuo = GLOBAL_CONFIG_SITE.isShuoshuo
  const option = null

  const destroyWaline = ele => ele.destroy()

  const initWaline = (Fn, el = document, path = window.location.pathname) => {
    const waline = Fn({
      el: el.querySelector('#waline-wrap'),
      serverURL: 'https://jvwbeje2.api.lncldglobal.com',
      pageview: true,
      dark: 'html[data-theme="dark"]',
      comment: true,
      ...option,
      path: isShuoshuo ? path : (option && option.path) || path
    })

    if (isShuoshuo) {
      window.shuoshuoComment.destroyWaline = () => {
        destroyWaline(waline)
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const loadWaline = (el, path) => {
    if (initFn) initWaline(initFn, el, path)
    else {
      btf.getCSS('https://cdn.jsdelivr.net/npm/@waline/client/dist/waline.min.css')
        .then(() => import('https://cdn.jsdelivr.net/npm/@waline/client/dist/waline.min.js'))
        .then(({ init }) => {
          initFn = init || Waline.init
          initWaline(initFn, el, path)
          window.walineFn = initFn
        })
    }
  }

  if (isShuoshuo) {
    'Waline' === 'Waline'
      ? window.shuoshuoComment = { loadComment: loadWaline } 
      : window.loadOtherComment = loadWaline
    return
  }

  if ('Waline' === 'Waline' || !false) {
    if (false) btf.loadComment(document.getElementById('waline-wrap'),loadWaline)
    else setTimeout(loadWaline, 0)
  } else {
    window.loadOtherComment = loadWaline
  }
})()</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>